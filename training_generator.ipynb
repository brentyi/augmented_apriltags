{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import transformations as t\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import os\n",
    "import threading\n",
    "\n",
    "def show_cv2(img):\n",
    "    # swap b and r channels\n",
    "    b, g, r = cv2.split(img)\n",
    "    img = cv2.merge([r,g,b])\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def plot_histogram(img):\n",
    "    color = ('b','g','r')\n",
    "    for i,col in enumerate(color):\n",
    "        histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "        plt.plot(histr,color = col)\n",
    "        plt.xlim([0,256])\n",
    "    plt.show()\n",
    "    \n",
    "def add_grayscale_noise(img, std_dev):\n",
    "    noise = np.expand_dims(np.random.normal(0, std_dev, size=img.shape[:2]).astype(np.int8), axis=2)\n",
    "    img = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def add_colored_noise(img, std_dev):\n",
    "    noise = np.random.normal(0, std_dev, size=img.shape).astype(np.int8)\n",
    "    img = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tags/tag36_11_00376.png ./places/Places365_val_00001162.jpg\n"
     ]
    }
   ],
   "source": [
    "def listfiles(path):\n",
    "    return [os.path.join(dp, f) for dp, dn, fn in os.walk(path) for f in fn]\n",
    "tag_urls = listfiles(\"./tags\")\n",
    "scene_urls = listfiles(\"./places\")\n",
    "\n",
    "print(tag_urls[0], scene_urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.47396747e+03 0.00000000e+00 5.69329599e+02]\n",
      " [0.00000000e+00 1.47391690e+03 3.79610277e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Populate some camera intrinsic settings\n",
    "# And other constants\n",
    "# To do: capitolize these variables names idk how to find and replace in this notebook\n",
    "\n",
    "#camera_intrinsics = [1.1998640834468974e+03, 0, 640.0 / 2, 0, 1.1998640834468974e+03, 480.0 / 2, 0, 0, 1]\n",
    "camera_intrinsics = [1473.967474, 0.000000, 569.329599, 0.000000, 1473.916904, 379.610277, 0.000000, 0.000000, 1.000000]\n",
    "camera_intrinsics = np.array(camera_intrinsics).reshape([3, 3])\n",
    "\n",
    "fx = camera_intrinsics[0,0]\n",
    "fy = camera_intrinsics[1,1]\n",
    "cx = camera_intrinsics[0,2]\n",
    "cy = camera_intrinsics[1,2]\n",
    "\n",
    "tag_size = 0.1\n",
    "\n",
    "print(camera_intrinsics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gen_sample(plot=False, low_res=False):\n",
    "    #img_scene = np.random.randint(0, 255, size=(768, 1024, 3)).astype(np.uint8)\n",
    "    white_background = False\n",
    "    if np.random.randint(20) == 1:\n",
    "        # Eliminate tag borders sometime to prevent overfitting\n",
    "        white_background = True\n",
    "\n",
    "    if not white_background:\n",
    "        img_scene = cv2.resize(cv2.imread(np.random.choice(scene_urls)), (1280, 720), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    img_tag = cv2.resize(cv2.imread(np.random.choice(tag_urls)), (200, 200), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    world_corners = np.array([[-1, -1], [1, -1], [-1, 1], [1, 1]]) * tag_size / 2.0\n",
    "    pixel_corners = np.array([[0, 0], [1, 0], [0, 1], [1, 1]]) * np.array(img_tag.shape)[:2]\n",
    "\n",
    "    # Add a Z component and homogeneous coordinate\n",
    "    corners_3d = np.hstack((world_corners, np.array([[0, 1]] * 4)))\n",
    "\n",
    "    done = False\n",
    "    attempts = 0\n",
    "    while not done:\n",
    "        # Apply a random rotation to our corners\n",
    "        angle_lim = np.pi / 2 * 0.7\n",
    "        #rotation_matrix = t.rotation_matrix(np.random.uniform(-angle_lim, angle_lim), [1, 0, 0])\n",
    "        #rotation_matrix = rotation_matrix @ t.rotation_matrix(np.random.uniform(-angle_lim, angle_lim), [0, 1, 0])\n",
    "        rand_vector = t.random_vector(3)\n",
    "        rand_vector[2]= 0\n",
    "        rand_vector /= np.linalg.norm(rand_vector)\n",
    "        rotation_matrix = t.rotation_matrix(np.random.uniform(-angle_lim, angle_lim), rand_vector)\n",
    "        #rotation_matrix = rotation_matrix @ t.rotation_matrix(np.random.uniform(-np.pi, np.pi), [0, 0, 1])\n",
    "        corners_3d_rotated = (rotation_matrix @ corners_3d.T).T\n",
    "\n",
    "        # Translate our corners to a random 3D point within our camera view\n",
    "        #z = np.random.triangular(0.2, 0.2, 5)\n",
    "        z = np.random.uniform(0.2, 3.5)\n",
    "        x = np.random.uniform(-1, 1) * z / fx * cx\n",
    "        y = np.random.uniform(-1, 1) * z / fy * cy\n",
    "        translation = np.array([x, y, z])\n",
    "        translation_matrix = t.translation_matrix(translation)\n",
    "        corners_3d_transformed = (translation_matrix @ corners_3d_rotated.T).T\n",
    "\n",
    "        # Project into 2D image space\n",
    "        projected_transformed = camera_intrinsics @ corners_3d_transformed.T[:3]\n",
    "        projected_transformed /= projected_transformed[2]\n",
    " \n",
    "        projected_transformed = np.vstack((projected_transformed[0], projected_transformed[1]))\n",
    "        # print(projected_transformed)\n",
    "\n",
    "        done = True\n",
    "        attempts += 1\n",
    "        for (x, y) in projected_transformed.T:\n",
    "            # Reject views that have tag corners chopped off\n",
    "            if x < 0 or y < 0 or x > 1280 or y > 720:\n",
    "                done = False\n",
    "\n",
    "    center_x, center_y = np.mean(projected_transformed, axis=1)\n",
    "    width = np.max(projected_transformed[0]) - np.min(projected_transformed[0])\n",
    "    height = np.max(projected_transformed[1]) - np.min(projected_transformed[1])\n",
    "\n",
    "    # print(attempts, \"attempt(s)\")\n",
    "\n",
    "    # Compute a homography\n",
    "    H = cv2.findHomography(pixel_corners, projected_transformed.T)[0]\n",
    "\n",
    "    # Random lighting condition\n",
    "    dynamic_range = np.random.uniform(0.4, 1.0)\n",
    "    color_shift =  (1.0 - dynamic_range) * np.random.uniform(0, 255) + np.random.normal(0.0, 10, size=3)\n",
    "\n",
    "    img_tag_lighting = img_tag * dynamic_range\n",
    "    img_tag_lighting += color_shift\n",
    "    img_tag_lighting = np.clip(img_tag_lighting, 0.0, 255.0).astype(np.uint8)\n",
    "    \n",
    "    img_tag_blank = np.zeros(img_tag.shape) + 255.0 * dynamic_range\n",
    "    img_tag_blank += color_shift\n",
    "    img_tag_blank = np.clip(img_tag_blank, 0.0, 255.0).astype(np.uint8)\n",
    "    \n",
    "    if white_background:\n",
    "        img_scene = np.clip(np.zeros((720, 1280, 3)) + 255.0 * dynamic_range + color_shift, 0.0, 255.0).astype(np.uint8)\n",
    "        img_scene = add_colored_noise(img_scene, 4)\n",
    "        img_scene = add_grayscale_noise(img_scene, 10)\n",
    "    \n",
    "    # Some noise\n",
    "    img_tag_filtered = cv2.GaussianBlur(img_tag_lighting, (3, 3), 0)\n",
    "    img_tag_filtered = add_colored_noise(img_tag_filtered, 4)\n",
    "    img_tag_filtered = add_grayscale_noise(img_tag_filtered, 10)\n",
    "    img_tag_blank = cv2.GaussianBlur(img_tag_blank, (3, 3), 0)\n",
    "    img_tag_blank = add_colored_noise(img_tag_blank, 4)\n",
    "    img_tag_blank = add_grayscale_noise(img_tag_blank, 10)\n",
    "    \n",
    "    # Overlay warped image\n",
    "    img_scene_with_tag = np.array(img_scene)\n",
    "    cv2.warpPerspective(img_tag_filtered, H, dsize=img_scene.shape[:2][::-1], dst=img_scene_with_tag, borderMode=cv2.BORDER_TRANSPARENT)\n",
    "    \n",
    "    if np.random.randint(3) == 1:\n",
    "        # put a blank rectangle on the \"to tag\" scene for some extra overfitting protection\n",
    "        cv2.warpPerspective(img_tag_blank, H, dsize=img_scene.shape[:2][::-1], dst=img_scene, borderMode=cv2.BORDER_TRANSPARENT)\n",
    "    blur_size = np.random.randint(4) * 2 + 1\n",
    "    img_scene_with_tag = cv2.GaussianBlur(img_scene_with_tag, (blur_size, blur_size), 0)\n",
    "    img_scene = cv2.GaussianBlur(img_scene, (blur_size, blur_size), 0)\n",
    "\n",
    "    # Bias our tag's color towards the image average color\n",
    "    img_tag_filtered = (img_tag_filtered * 49.0 / 50.0 + (np.mean(img_scene,axis=(0,1)) / 50.0).astype(np.int16)).astype(np.uint8)\n",
    "\n",
    "    # Plot?\n",
    "    if plot:\n",
    "        show_cv2(img_tag_filtered)\n",
    "        \n",
    "        show_cv2(img_tag_blank)\n",
    "        \n",
    "#         # Visualize in 3D\n",
    "#         fig = plt.figure()\n",
    "#         ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "#         xs = corners_3d.T[0]\n",
    "#         ys = corners_3d.T[1]\n",
    "#         zs = corners_3d.T[2]\n",
    "#         ax.scatter(xs, ys, zs)\n",
    "\n",
    "#         xs = corners_3d_transformed.T[0]\n",
    "#         ys = corners_3d_transformed.T[1]\n",
    "#         zs = corners_3d_transformed.T[2]\n",
    "#         ax.scatter(xs, ys, zs)\n",
    "\n",
    "#         # Visualize in 3D\n",
    "#         plt.figure()\n",
    "#         plt.ylim(0, cy * 2)\n",
    "#         plt.xlim(0, cx * 2)\n",
    "\n",
    "        #xs = projected_orig[0]\n",
    "        #ys = projected_orig[1]\n",
    "        #plt.scatter(xs, ys)\n",
    "#         xs = projected_transformed[0]\n",
    "#         ys = projected_transformed[1]\n",
    "#         plt.plot(xs, ys)\n",
    "\n",
    "#         plt.show()\n",
    "        \n",
    "        # Visualize the scene + histograms\n",
    "#         plot_histogram(img_scene)\n",
    "        show_cv2(img_scene)\n",
    "\n",
    "#         plot_histogram(img_scene_with_tag)\n",
    "        show_cv2(img_scene_with_tag)\n",
    "        \n",
    "        show_cv2(cv2.resize(img_scene_with_tag, (640, 360), interpolation=cv2.INTER_NEAREST))\n",
    "    \n",
    "    width += 5\n",
    "    height += 5\n",
    "    if low_res:\n",
    "        resize = lambda x: cv2.resize(x, (640, 360), interpolation=cv2.INTER_NEAREST)\n",
    "        img_scene, img_scene_with_tag = resize(img_scene), resize(img_scene_with_tag)\n",
    "        center_x /= 2\n",
    "        width /= 2\n",
    "        center_y /= 2\n",
    "        height /= 2\n",
    "    return img_scene, img_scene_with_tag, center_x, center_y, width, height\n",
    "\n",
    "# gen_sample(False, True)\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-13e2ef106e4e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mimg_scene\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_scene_with_tag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# train_labels.csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-f8659fbe4f27>\u001b[0m in \u001b[0;36mgen_sample\u001b[1;34m(plot, low_res)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwhite_background\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mimg_scene\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m720\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1280\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m255.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdynamic_range\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcolor_shift\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mimg_scene\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_colored_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_scene\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mimg_scene\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_grayscale_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_scene\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-0de0af74e022>\u001b[0m in \u001b[0;36madd_colored_noise\u001b[1;34m(img, std_dev)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_colored_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test for generating training sample\n",
    "\n",
    "fd = open(\"generated_data_labels.csv\", \"w\")\n",
    "fd.write(\"filename,width,height,class,xmin,ymin,xmax,ymin\\r\\n\")\n",
    "fd.close()\n",
    "\n",
    "for count in range(10000):\n",
    "    img_scene, img_scene_with_tag, center_x, center_y, bbox_width, bbox_height = gen_sample()\n",
    "\n",
    "    # train_labels.csv\n",
    "    # columns as filename,width,height,class,xmin,ymin,xmax,ymin\n",
    "\n",
    "    filename = \"generated_data/sample_{}.jpg\".format(count)\n",
    "    width = img_scene_with_tag.shape[1]\n",
    "    height = img_scene_with_tag.shape[0]\n",
    "    class_label = \"tag\"\n",
    "    min_x = int(center_x - bbox_width / 2)\n",
    "    min_y = int(center_y - bbox_height / 2)\n",
    "    max_x = int(center_x + bbox_width / 2)\n",
    "    max_y = int(center_y + bbox_height / 2)\n",
    "\n",
    "    elements = [filename, width, height, class_label, min_x, min_y, max_x, max_y]\n",
    "    row = \",\".join([str(x) for x in elements])\n",
    "    fd = open(\"generated_data_labels.csv\",\"a\")\n",
    "    fd.write(row + \"\\r\\n\")\n",
    "    fd.close()\n",
    "\n",
    "    # cv2.rectangle(img_scene_with_tag, (min_x, min_y), (max_x, max_y), (0, 0, 255), thickness=2)\n",
    "    # show_cv2(img_scene_with_tag)\n",
    "\n",
    "    cv2.imwrite(filename, img_scene_with_tag, [int(cv2.IMWRITE_JPEG_QUALITY), 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
